params
}
if(model == "StMAR" | model == "G-StMAR") {
initvalues <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=initvalues[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Create initial values
cat("Optimizing with the simulated annealing...\n")
SANNresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=initvalues[[i1]], fn=f, method=c("SANN"),
control=list(fnscale=-1, maxit=100))[[1]], cl=cl)
parallel::stopCluster(cl=cl)
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=exp))
}
loks <- vapply(1:ncalls, function(i1) loglikelihood_int(data=data, p=p, M=M, params=SANNresults[[i1]], model=model,
restricted=restricted, constraints=constraints, conditional=conditional,
parametrization=parametrization, boundaries=TRUE, checks=FALSE,
minval=minval), numeric(1))
if(printRes) {
printloks <- function() {
printfun <- function(txt, FUN) cat(paste(txt, round(FUN(loks), 3)), "\n")
printfun("The lowest loglik: ", min)
printfun("The mean loglik:   ", mean)
printfun("The largest loglik:", max)
}
cat("Results from simulated annealing:\n")
printloks()
}
### Optimization with the variable metric algorithm ###
# Logarithmize dfs to get overly large dfs values to the same range as other parameters.
# This adjusts the difference 'h' larger for larger dfs parameters in non-log scale to
# avoid numerical problems associated with overly large degrees of freedom values, and
# it also allows the dfs estimates to 'explode' more sensitively.
manipulateDFS <- function(M, params, model, FUN) {
FUN <- match.fun(FUN)
M2 <- ifelse(model == "StMAR", M, M[2])
params[(d - M2 + 1):d] <- FUN(params[(d - M2 + 1):d])
params
}
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Calculate gradient of the log-likelihood function using central finite difference approximation
I <- diag(rep(1, d))
h <- 6e-6
gr <- function(params) {
vapply(1:d, function(i1) (f(params + I[i1,]*h) - f(params - I[i1,]*h))/(2*h), numeric(1))
}
cl <- parallel::makeCluster(ncores)
parallel::clusterExport(cl, ls(environment(fitGSMAR)), envir = environment(fitGSMAR)) # assign all variables from package:uGMAR
parallel::clusterEvalQ(cl, c(library(Brobdingnag), library(pbapply)))
cat("Optimizing with the variable metric algorithm...\n")
NEWTONresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=SANNresults[[i1]], fn=f, gr=gr, method=c("BFGS"),
control=list(fnscale=-1, maxit=maxit)), cl=cl)
parallel::stopCluster(cl=cl)
loks <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$value, numeric(1))
converged <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$convergence == 0, logical(1))
if(is.null(constraints)) {
newtonEstimates <- lapply(1:ncalls, function(i1) sortComponents(p=p, M=M, params=NEWTONresults[[i1]]$par, model=model, restricted=restricted))
} else {
newtonEstimates <- lapply(1:ncalls, function(i1) NEWTONresults[[i1]]$par)
}
# Unlogarithmize dfs
if(model == "StMAR" | model == "G-StMAR") {
newtonEstimates <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=newtonEstimates[[i1]], model=model, FUN=exp))
}
if(printRes) {
cat("Results from the variable metric algorithm:\n")
printloks()
}
# Obtain the estimates
bestind <- which(loks == max(loks))[1]
bestfit <- NEWTONresults[[bestind]]
params <- newtonEstimates[[bestind]]
mw <- mixingWeights_int(data, p, M, params, model=model, restricted=restricted, constraints=constraints,
parametrization=parametrization, to_return="mw")
# Warnings and notifications
if(any(vapply(1:sum(M), function(i1) sum(mw[,i1] > red_criteria[1]) < red_criteria[2]*length(data), logical(1)))) {
message("At least one of the mixture components in the estimated model seems to be wasted!")
}
if(bestfit$convergence == 1) message("Iteration limit was reached when estimating the best fitting individual! Iterate more with the function 'iterate_more'.")
# Quantile residual tests
if(runTests) {
cat("Performing quantile residual tests...\n")
tmp_gsmar <- GSMAR(data, p, M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_std_errors=FALSE)
qr_tests <- quantileResidualTests(tmp_gsmar, lagsAC=c(1, 2, 5, 10), lagsCH=c(1, 2, 5, 10), nsimu=2000, printRes=printRes)
if(printRes) cat("\n")
} else {
qr_tests <- NULL
}
### Wrap up ###
ret <- GSMAR(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_qresiduals=TRUE,
calc_cond_moments=TRUE, calc_std_errors=TRUE)
ret$all_estimates <- newtonEstimates
ret$all_logliks <- loks
ret$which_converged <- converged
ret$qrtests <- qr_tests
cat("Finished!\n")
ret
}
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=1)
fit12GA
fit12GA$loglik
fit12SANN
fit12SANN$loglik
fit12GA$loglik
plot(fit12SANN)
# Fit with SANN + variable nmetric algorithm
fitSANN <- function(data, p, M, model=c("GMAR", "StMAR", "G-StMAR"), restricted=FALSE, constraints=NULL, conditional=TRUE,
parametrization=c("intercept", "mean"), ncalls=round(10 + 9*log(sum(M))), ncores=min(2, ncalls, parallel::detectCores()),
maxit=300, seeds=NULL, printRes=TRUE, runTests=FALSE) {
on.exit(closeAllConnections())
if(!all_pos_ints(c(ncalls, ncores, maxit))) stop("Arguments ncalls, ncores and maxit have to be positive integers")
if(!is.null(seeds) && length(seeds) != ncalls) stop("The argument 'seeds' needs be NULL or a vector of length 'ncalls'")
model <- match.arg(model)
check_model(model)
parametrization <- match.arg(parametrization)
checkPM(p, M, model=model)
data <- checkAndCorrectData(data, p)
checkConstraintMat(p, M, restricted=restricted, constraints=constraints)
d <- nParams(p=p, M=M, model=model, restricted=restricted, constraints=constraints)
minval <- get_minval(data)
red_criteria <- c(0.05, 0.01)
if(ncalls < ncores) {
ncores <- ncalls
message("ncores was set to be larger than the number of estimation rounds: using ncores = ncalls")
}
cat(paste("Using", ncores, "cores for", ncalls, "estimation rounds..."), "\n")
### Optimization with the genetic algorithm ###
# initial values
initvalues <- lapply(1:ncalls, function(i1) randomIndividual(p=p, M=M, model=model, restricted=FALSE, constraints=NULL,
meanscale = c(mean(data), sd(data)),
sigmascale =  var(stats::ar(data, order.max=10)$resid, na.rm=TRUE)))
cl <- parallel::makeCluster(ncores)
parallel::clusterExport(cl, ls(environment(fitGSMAR)), envir=environment(fitGSMAR)) # assign all variables from package:uGMAR
parallel::clusterEvalQ(cl, c(library(Brobdingnag), library(pbapply)))
manipulateDFS <- function(M, params, model, FUN) {
FUN <- match.fun(FUN)
M2 <- ifelse(model == "StMAR", M, M[2])
params[(d - M2 + 1):d] <- FUN(params[(d - M2 + 1):d])
params
}
if(model == "StMAR" | model == "G-StMAR") {
initvalues <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=initvalues[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Create initial values
cat("Optimizing with the simulated annealing...\n")
SANNresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=initvalues[[i1]], fn=f, method=c("SANN"),
control=list(fnscale=-1, maxit=10000))[[1]], cl=cl)
parallel::stopCluster(cl=cl)
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=exp))
}
loks <- vapply(1:ncalls, function(i1) loglikelihood_int(data=data, p=p, M=M, params=SANNresults[[i1]], model=model,
restricted=restricted, constraints=constraints, conditional=conditional,
parametrization=parametrization, boundaries=TRUE, checks=FALSE,
minval=minval), numeric(1))
if(printRes) {
printloks <- function() {
printfun <- function(txt, FUN) cat(paste(txt, round(FUN(loks), 3)), "\n")
printfun("The lowest loglik: ", min)
printfun("The mean loglik:   ", mean)
printfun("The largest loglik:", max)
}
cat("Results from simulated annealing:\n")
printloks()
}
### Optimization with the variable metric algorithm ###
# Logarithmize dfs to get overly large dfs values to the same range as other parameters.
# This adjusts the difference 'h' larger for larger dfs parameters in non-log scale to
# avoid numerical problems associated with overly large degrees of freedom values, and
# it also allows the dfs estimates to 'explode' more sensitively.
manipulateDFS <- function(M, params, model, FUN) {
FUN <- match.fun(FUN)
M2 <- ifelse(model == "StMAR", M, M[2])
params[(d - M2 + 1):d] <- FUN(params[(d - M2 + 1):d])
params
}
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Calculate gradient of the log-likelihood function using central finite difference approximation
I <- diag(rep(1, d))
h <- 6e-6
gr <- function(params) {
vapply(1:d, function(i1) (f(params + I[i1,]*h) - f(params - I[i1,]*h))/(2*h), numeric(1))
}
cl <- parallel::makeCluster(ncores)
parallel::clusterExport(cl, ls(environment(fitGSMAR)), envir = environment(fitGSMAR)) # assign all variables from package:uGMAR
parallel::clusterEvalQ(cl, c(library(Brobdingnag), library(pbapply)))
cat("Optimizing with the variable metric algorithm...\n")
NEWTONresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=SANNresults[[i1]], fn=f, gr=gr, method=c("BFGS"),
control=list(fnscale=-1, maxit=maxit)), cl=cl)
parallel::stopCluster(cl=cl)
loks <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$value, numeric(1))
converged <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$convergence == 0, logical(1))
if(is.null(constraints)) {
newtonEstimates <- lapply(1:ncalls, function(i1) sortComponents(p=p, M=M, params=NEWTONresults[[i1]]$par, model=model, restricted=restricted))
} else {
newtonEstimates <- lapply(1:ncalls, function(i1) NEWTONresults[[i1]]$par)
}
# Unlogarithmize dfs
if(model == "StMAR" | model == "G-StMAR") {
newtonEstimates <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=newtonEstimates[[i1]], model=model, FUN=exp))
}
if(printRes) {
cat("Results from the variable metric algorithm:\n")
printloks()
}
# Obtain the estimates
bestind <- which(loks == max(loks))[1]
bestfit <- NEWTONresults[[bestind]]
params <- newtonEstimates[[bestind]]
mw <- mixingWeights_int(data, p, M, params, model=model, restricted=restricted, constraints=constraints,
parametrization=parametrization, to_return="mw")
# Warnings and notifications
if(any(vapply(1:sum(M), function(i1) sum(mw[,i1] > red_criteria[1]) < red_criteria[2]*length(data), logical(1)))) {
message("At least one of the mixture components in the estimated model seems to be wasted!")
}
if(bestfit$convergence == 1) message("Iteration limit was reached when estimating the best fitting individual! Iterate more with the function 'iterate_more'.")
# Quantile residual tests
if(runTests) {
cat("Performing quantile residual tests...\n")
tmp_gsmar <- GSMAR(data, p, M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_std_errors=FALSE)
qr_tests <- quantileResidualTests(tmp_gsmar, lagsAC=c(1, 2, 5, 10), lagsCH=c(1, 2, 5, 10), nsimu=2000, printRes=printRes)
if(printRes) cat("\n")
} else {
qr_tests <- NULL
}
### Wrap up ###
ret <- GSMAR(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_qresiduals=TRUE,
calc_cond_moments=TRUE, calc_std_errors=TRUE)
ret$all_estimates <- newtonEstimates
ret$all_logliks <- loks
ret$which_converged <- converged
ret$qrtests <- qr_tests
cat("Finished!\n")
ret
}
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=1)
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=15, ncores=3)
fit12SANN
fit12GA <- fitGSMAR(sample12, 1, 2, ncores=3, ncalls=15) # 1min 10s, all get the same estimate
# Fit with SANN + variable nmetric algorithm
fitSANN <- function(data, p, M, model=c("GMAR", "StMAR", "G-StMAR"), restricted=FALSE, constraints=NULL, conditional=TRUE,
parametrization=c("intercept", "mean"), ncalls=round(10 + 9*log(sum(M))), ncores=min(2, ncalls, parallel::detectCores()),
maxit=300, seeds=NULL, printRes=TRUE, runTests=FALSE, SANNmaxit=10000) {
on.exit(closeAllConnections())
if(!all_pos_ints(c(ncalls, ncores, maxit))) stop("Arguments ncalls, ncores and maxit have to be positive integers")
if(!is.null(seeds) && length(seeds) != ncalls) stop("The argument 'seeds' needs be NULL or a vector of length 'ncalls'")
model <- match.arg(model)
check_model(model)
parametrization <- match.arg(parametrization)
checkPM(p, M, model=model)
data <- checkAndCorrectData(data, p)
checkConstraintMat(p, M, restricted=restricted, constraints=constraints)
d <- nParams(p=p, M=M, model=model, restricted=restricted, constraints=constraints)
minval <- get_minval(data)
red_criteria <- c(0.05, 0.01)
if(ncalls < ncores) {
ncores <- ncalls
message("ncores was set to be larger than the number of estimation rounds: using ncores = ncalls")
}
cat(paste("Using", ncores, "cores for", ncalls, "estimation rounds..."), "\n")
### Optimization with the genetic algorithm ###
# initial values
initvalues <- lapply(1:ncalls, function(i1) randomIndividual(p=p, M=M, model=model, restricted=FALSE, constraints=NULL,
meanscale = c(mean(data), sd(data)),
sigmascale =  var(stats::ar(data, order.max=10)$resid, na.rm=TRUE)))
cl <- parallel::makeCluster(ncores)
parallel::clusterExport(cl, ls(environment(fitGSMAR)), envir=environment(fitGSMAR)) # assign all variables from package:uGMAR
parallel::clusterEvalQ(cl, c(library(Brobdingnag), library(pbapply)))
manipulateDFS <- function(M, params, model, FUN) {
FUN <- match.fun(FUN)
M2 <- ifelse(model == "StMAR", M, M[2])
params[(d - M2 + 1):d] <- FUN(params[(d - M2 + 1):d])
params
}
if(model == "StMAR" | model == "G-StMAR") {
initvalues <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=initvalues[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Create initial values
cat("Optimizing with the simulated annealing...\n")
SANNresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=initvalues[[i1]], fn=f, method=c("SANN"),
control=list(fnscale=-1, maxit=SANNmaxit))[[1]], cl=cl)
parallel::stopCluster(cl=cl)
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=exp))
}
loks <- vapply(1:ncalls, function(i1) loglikelihood_int(data=data, p=p, M=M, params=SANNresults[[i1]], model=model,
restricted=restricted, constraints=constraints, conditional=conditional,
parametrization=parametrization, boundaries=TRUE, checks=FALSE,
minval=minval), numeric(1))
if(printRes) {
printloks <- function() {
printfun <- function(txt, FUN) cat(paste(txt, round(FUN(loks), 3)), "\n")
printfun("The lowest loglik: ", min)
printfun("The mean loglik:   ", mean)
printfun("The largest loglik:", max)
}
cat("Results from simulated annealing:\n")
printloks()
}
### Optimization with the variable metric algorithm ###
# Logarithmize dfs to get overly large dfs values to the same range as other parameters.
# This adjusts the difference 'h' larger for larger dfs parameters in non-log scale to
# avoid numerical problems associated with overly large degrees of freedom values, and
# it also allows the dfs estimates to 'explode' more sensitively.
manipulateDFS <- function(M, params, model, FUN) {
FUN <- match.fun(FUN)
M2 <- ifelse(model == "StMAR", M, M[2])
params[(d - M2 + 1):d] <- FUN(params[(d - M2 + 1):d])
params
}
if(model == "StMAR" | model == "G-StMAR") {
SANNresults <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=SANNresults[[i1]], model=model, FUN=log))
}
# Function to maximize loglikelihood
f <- function(params) {
if(model == "StMAR" | model == "G-StMAR") {
params <- manipulateDFS(M=M, params=params, model=model, FUN=exp) # Unlogarithmize dfs for calculating log-likelihood
}
tryCatch(loglikelihood_int(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, boundaries=TRUE, checks=FALSE, minval=minval),
error=function(e) minval)
}
# Calculate gradient of the log-likelihood function using central finite difference approximation
I <- diag(rep(1, d))
h <- 6e-6
gr <- function(params) {
vapply(1:d, function(i1) (f(params + I[i1,]*h) - f(params - I[i1,]*h))/(2*h), numeric(1))
}
cl <- parallel::makeCluster(ncores)
parallel::clusterExport(cl, ls(environment(fitGSMAR)), envir = environment(fitGSMAR)) # assign all variables from package:uGMAR
parallel::clusterEvalQ(cl, c(library(Brobdingnag), library(pbapply)))
cat("Optimizing with the variable metric algorithm...\n")
NEWTONresults <- pbapply::pblapply(1:ncalls, function(i1) optim(par=SANNresults[[i1]], fn=f, gr=gr, method=c("BFGS"),
control=list(fnscale=-1, maxit=maxit)), cl=cl)
parallel::stopCluster(cl=cl)
loks <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$value, numeric(1))
converged <- vapply(1:ncalls, function(i1) NEWTONresults[[i1]]$convergence == 0, logical(1))
if(is.null(constraints)) {
newtonEstimates <- lapply(1:ncalls, function(i1) sortComponents(p=p, M=M, params=NEWTONresults[[i1]]$par, model=model, restricted=restricted))
} else {
newtonEstimates <- lapply(1:ncalls, function(i1) NEWTONresults[[i1]]$par)
}
# Unlogarithmize dfs
if(model == "StMAR" | model == "G-StMAR") {
newtonEstimates <- lapply(1:ncalls, function(i1) manipulateDFS(M=M, params=newtonEstimates[[i1]], model=model, FUN=exp))
}
if(printRes) {
cat("Results from the variable metric algorithm:\n")
printloks()
}
# Obtain the estimates
bestind <- which(loks == max(loks))[1]
bestfit <- NEWTONresults[[bestind]]
params <- newtonEstimates[[bestind]]
mw <- mixingWeights_int(data, p, M, params, model=model, restricted=restricted, constraints=constraints,
parametrization=parametrization, to_return="mw")
# Warnings and notifications
if(any(vapply(1:sum(M), function(i1) sum(mw[,i1] > red_criteria[1]) < red_criteria[2]*length(data), logical(1)))) {
message("At least one of the mixture components in the estimated model seems to be wasted!")
}
if(bestfit$convergence == 1) message("Iteration limit was reached when estimating the best fitting individual! Iterate more with the function 'iterate_more'.")
# Quantile residual tests
if(runTests) {
cat("Performing quantile residual tests...\n")
tmp_gsmar <- GSMAR(data, p, M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_std_errors=FALSE)
qr_tests <- quantileResidualTests(tmp_gsmar, lagsAC=c(1, 2, 5, 10), lagsCH=c(1, 2, 5, 10), nsimu=2000, printRes=printRes)
if(printRes) cat("\n")
} else {
qr_tests <- NULL
}
### Wrap up ###
ret <- GSMAR(data=data, p=p, M=M, params=params, model=model, restricted=restricted, constraints=constraints,
conditional=conditional, parametrization=parametrization, calc_qresiduals=TRUE,
calc_cond_moments=TRUE, calc_std_errors=TRUE)
ret$all_estimates <- newtonEstimates
ret$all_logliks <- loks
ret$which_converged <- converged
ret$qrtests <- qr_tests
cat("Finished!\n")
ret
}
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=15, ncores=3, SANNmaxit=20000) # 25s
randomIndividual(p=4, M=3, "StMAR", meanscale=c(0, 10), sigmascale=10)
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=15, ncores=3, SANNmaxit=50000) # 25s
randomIndividual(p=4, M=3, "StMAR", meanscale=c(0, 10), sigmascale=10, forcestat = TRUE)
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=15, ncores=3, SANNmaxit=50000) # 25s
fit12GA
fit12GA$loglik
fit12SANN
plot(fit12SANN)
fit12SANN$all_logliks
fit12GA
ploto(fit12GA)
plot(fit12GA)
fit12GA$all_logliks
alt_gsmar(fit12GA, 1)
stmar43 <- GSMAR(p=4, M=3, params=params, model="StMAR")
## Simulated from more complicated StMAR(4,3) model
params <-  c(-12, -0.264, 1.583, 0.273, -0.673, 3.79, 11.31, -0.233, 0.002, 0.56, 0.42, 3.9,
-10.78, 0.14, 0.108, -0.417, 0.56, 2.78, 0.37, 0.32, 2.39, 2.04, 2.02)
stmar43 <- GSMAR(p=4, M=3, params=params, model="StMAR")
set.seed(2); sample43 <- simulateGSMAR(stmar43, nsimu=2000)
set.seed(2); sample43 <- simulateGSMAR(stmar43, nsimu=2000)$sample
fit43GA <- fitGSMAR(sample43gs, p=4, M=3, model="StMAR", ncalls=15, ncores=3)
fit43GA <- fitGSMAR(sample43, p=4, M=3, model="StMAR", ncalls=15, ncores=3)
fit12GA
fit43GA
fit43SANN <- fitSANN(sample43, p=4, M=3, model="StMAR", ncalls=15, ncores=3, SANNmaxit=10000)
fitSANN
fit43SANN
plot(fit43SANN)
plot(fit43GA)
stmar43d <- add_data(sample43, stmar43)
plot(stmar43d)
simulateGSMAR(stmar43, nsimu=2000)
set.seed(3); sample43 <- simulateGSMAR(stmar43, nsimu=2000)$sample
simulateGSMAR(stmar43, nsimu=2000)
stmar43
stmar43 <- GSMAR(p=4, M=3, params=params, model="StMAR", parametrization = "mean")
stmar43
set.seed(2); sample43 <- simulateGSMAR(stmar43, nsimu=2000)$sample
simulateGSMAR(stmar43, nsimu=2000)
stmar43
## Simulated from more complicated StMAR(4,3) model
params <-  c(-12, -0.264, 1.583, 0.273, -0.673, 3.79, -11.31, -0.233, 0.002, 0.56, 0.42, 3.9,
-10.78, 0.14, 0.108, -0.417, 0.56, 2.78, 0.37, 0.32, 2.39, 2.04, 2.02)
stmar43 <- GSMAR(p=4, M=3, params=params, model="StMAR", parametrization = "mean")
set.seed(2); sample43 <- simulateGSMAR(stmar43, nsimu=2000)$sample
simulateGSMAR(stmar43, nsimu=2000)
set.seed(2); sample43 <- simulateGSMAR(stmar43, nsimu=2000)$sample
stmar43d <- add_data(sample43, stmar43)
plot(stmar43d)
fit43GA <- fitGSMAR(sample43, p=4, M=3, model="StMAR", ncalls=15, ncores=3)
fit43SANN <- fitSANN(sample43, p=4, M=3, model="StMAR", ncalls=15, ncores=3, SANNmaxit=10000)
plot(fitGA43)
plot(fit43GA)
fit12SANN <- fitSANN(sample12, 1, 2, ncalls=15, ncores=3, SANNmaxit=50000) # 25s
fit12GA$loglik
fit43SANN <- fitSANN(sample43, p=4, M=3, model="StMAR", ncalls=15, ncores=3, SANNmaxit=50000)
fit43SANN
fit43SANN$all_logliks
fit12GA$all_logliks
fit43GA$all_logliks
## Simulated from StMAR(4,4) model
params <-  c(-12, -0.264, 1.583, 0.273, -0.673, 3.79, -8.31, -0.233, 0.002, 0.56, 0.42, 3.9,
-10.78, 0.14, 0.108, -0.417, 0.56, 2.78, -8.78, 0.56, 0.108, -0.417, -0.1, 2.78,
0.32, 0.30, 0.25, 2.39, 2.04, 2.02, 7)
stmar44 <- GSMAR(p=4, M=4, params=params, model="StMAR", parametrization = "mean")
set.seed(42); sample44 <- simulateGSMAR(stmar44, nsimu=2000)$sample
stmar44 <- add_data(sample44, stmar44)
plot(stmar44)
set.seed(44); sample44 <- simulateGSMAR(stmar44, nsimu=2000)$sample
stmar44 <- add_data(sample44, stmar44)
plot(stmar44)
fit44GA <- fitGSMAR(sample44, p=4, M=4, model="StMAR", ncalls=15, ncores=3)
fit44SANN <- fitSANN(sample44, p=4, M=4, model="StMAR", ncalls=15, ncores=3, SANNmaxit=50000)
fit44GA$all_logliks
fit44SANN$all_logliks
plot(fit44GA)
